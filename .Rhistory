Final_Status = last(diagnosis),
Transition     = paste(Initial_Status, "-", Final_Status),
Change_Type    = case_when(
Initial_Status == "CN"  & Final_Status == "CN"  ~ "StableCN",
Initial_Status == "CN"  & Final_Status == "MCI" ~ "CNtransitMCI",
Initial_Status == "MCI" & Final_Status == "CN"  ~ "MCItransitCN",
Initial_Status == "MCI" & Final_Status == "MCI" ~ "StableMCI",
Initial_Status == "MCI" & Final_Status == "AD"  ~ "MCItransitAD",
Initial_Status == "CN"  & Final_Status == "AD"  ~ "CNtransitAD",
Initial_Status == "AD"  & Final_Status == "MCI" ~ "ADtransitMCI",
Initial_Status == "AD"  & Final_Status == "CN"  ~ "ADtransitCN",
Initial_Status == "AD"  & Final_Status == "AD"  ~ "StableAD",
TRUE ~ NA_character_
),
visit_count = n(),
baseline_date = first(datetest),
elapsed_years = as.numeric(difftime(datetest, baseline_date, units = "days")) / 365.25,
elapsed_years_First_to_Last = as.numeric(difftime(last(datetest), first(datetest), units = "days")) / 365.25
) %>%
ungroup()
df4 <- df3 %>%
filter(elapsed_years_First_to_Last >= 0.916666666)
library(tableone)
library(effsize)
df_baseline$SEX <- as.factor(df_baseline$SEX)
df_baseline$Change_Type <- as.factor(df_baseline$Change_Type)
vars_table1 <- c('SEX','AGE','EDUYR','gds','kdsq','visitcount','MMSE',
'SNSB_attention','SNSB_language','SNSB_visuospatial','SNSB_memory','SNSB_frontal')
vars_table2 <- c('height','weight','Waistcir','Hipcir','sysbp','diabp','bmi','ac','whr',
'pbcm','pbf','bmr','tbw_ffm','ecw_tcw','PA50_total')
vars_table3 <- c('ECW_ICW_upper','ECW_ICW_lower','Water_Lean_upper','Water_Lean_lower',
'R_upper','R_lower','Xc_upper','Xc_lower','PA_upper','PA_lower',
'R_H_upper','R_H_lower','Xc_H_upper','Xc_H_lower')
group_var <- "Change_Type"
covars <- c("AGE", "SEX", "EDUYR")
tab1 <- CreateTableOne(vars=vars_table1, strata=group_var, data=df_baseline)
print(tab1, showAllLevels=TRUE, quote=TRUE, noSpaces=TRUE)
get_pvals_es <- function(varlist, groupvar, df){
res <- lapply(varlist, function(v){
vals <- df[[v]]; g <- df[[groupvar]]
non_missing <- !(is.na(vals) | is.na(g))
vals_nm <- vals[non_missing]
g_nm <- g[non_missing]
pval <- NA; effsize <- NA
if (length(unique(g_nm)) != 2) return(list(pval=NA,effsize=NA))
if (is.numeric(vals_nm) | is.integer(vals_nm)){
p_norm <- tryCatch(shapiro.test(vals_nm)$p.value,error=function(e) NA)
if (!is.na(p_norm) && p_norm > 0.05){
ttest <- t.test(vals_nm ~ g_nm)
pval <- ttest$p.value
effsize <- effsize::cohen.d(vals_nm, g_nm)$estimate
}else{
wilcox <- wilcox.test(vals_nm ~ g_nm)
pval <- wilcox$p.value
effsize <- effsize::cohen.d(vals_nm, g_nm, hedges.correction=TRUE)$estimate
}
}else{
tbl <- table(vals_nm, g_nm)
pval <- if(any(tbl < 5)) fisher.test(tbl)$p.value else chisq.test(tbl)$p.value
effsize <- NA
}
return(list(pval=pval,effsize=effsize))
})
names(res) <- varlist
return(res)
}
result_table1 <- get_pvals_es(vars_table1, group_var, df_baseline)
print(result_table1)
get_group_coef <- function(res, group_var, df) {
levs <- levels(df[[group_var]])
target_lev <- levs[2]
target_name <- grep(target_lev, rownames(coef(res)), value=TRUE)
if(length(target_name) == 1) {
pval <- coef(res)[target_name, "Pr(>|t|)"]
est <- coef(res)[target_name, "Estimate"]
} else {
pval <- NA
est <- NA
}
return(list(pval=pval, estimate=est))
}
ancova_tab2 <- lapply(vars_table2, function(v){
formula <- as.formula(paste(v, "~", group_var, "+ AGE + SEX + EDUYR"))
model <- lm(formula, data=df_baseline, na.action=na.exclude)
res <- summary(model)
grp <- get_group_coef(res, group_var, df_baseline)
return(list(pval=grp$pval, estimate=grp$estimate, model=res))
})
names(ancova_tab2) <- vars_table2
ancova_tab3 <- lapply(vars_table3, function(v){
formula <- as.formula(paste(v, "~", group_var, "+ AGE + SEX + EDUYR"))
model <- lm(formula, data=df_baseline, na.action=na.exclude)
res <- summary(model)
grp <- get_group_coef(res, group_var, df_baseline)
return(list(pval=grp$pval, estimate=grp$estimate, model=res))
})
names(ancova_tab3) <- vars_table3
print_ancova <- function(res_list, units = NULL) {
for (v in names(res_list)) {
est <- res_list[[v]]$estimate
pval <- res_list[[v]]$pval
u <- if(!is.null(units) && !is.na(units[v])) units[v] else ""
cat(sprintf("%-25s Estimate: %8.3f %-5s | p-value: %.4f\n", v, est, u, pval))
}
}
units_table2 <- c(height = "cm", weight = "kg", BMI = "", whr = "", pbcm = "%", pbf = "%", bmr = "kcal", ecw_tcw = "%", tbw_ffm = "%", PA50_total = "degree")
units_table3 <- c(
ECW_ICW_upper = "%", ECW_ICW_lower = "%", Water_Lean_upper = "%", Water_Lean_lower = "%",
R_upper = "Ω", R_lower = "Ω", Xc_upper = "Ω", Xc_lower = "Ω", PA_upper = "degree", PA_lower = "degree",
R_H_upper = "Ω", R_H_lower = "Ω", Xc_H_upper = "Ω", Xc_H_lower = "Ω"
)
cat("\n===== Table 2: ANCOVA Results =====\n")
print_ancova(ancova_tab2, units_table2)
cat("\n===== Table 3: ANCOVA Results =====\n")
print_ancova(ancova_tab3, units_table3)
ggplot(df_baseline, aes(x=Change_Type, y=R_lower, fill=Change_Type)) +
geom_violin(trim=FALSE) +
geom_boxplot(width=0.1, fill="white") +
labs(title="R_lower by Group", y="R_lower") +
theme_minimal()
#write.csv(print(tab1, quote = TRUE, noSpaces = TRUE), "table1_baseline.csv")
tbl2_results <- sapply(names(ancova_tab2), function(var) c(Estimate = ancova_tab2[[var]]$estimate, Pvalue = ancova_tab2[[var]]$pval))
#write.csv(tbl2_results, "table2_ancova.csv")
tbl3_results <- sapply(names(ancova_tab3), function(var) c(Estimate = ancova_tab3[[var]]$estimate, Pvalue = ancova_tab3[[var]]$pval))
#write.csv(tbl3_results, "table3_ancova.csv")
# Data manipulation
library(dplyr)
library(tidyr)
library(tibble)
library(lubridate)
library(stringr)
# Visualization
library(ggplot2)
library(cowplot)
library(ggpubr)
library(patchwork)
library(sjPlot)
# Statistical analysis
library(lme4)
library(lmerTest)
library(rstatix)
library(effectsize)
library(emmeans)
library(broom)
library(broom.mixed)
# Reporting
library(gtsummary)
library(flextable)
library(summarytools)
# Read your data ( KIOM_USER or admin )
setwd("C:/Users/admin/Documents/GitHub/LongitudinalNC")
# Read your data ( KIOM_USER or admin )
setwd("C:/KIOM_USER/admin/Documents/GitHub/LongitudinalNC")
# Read your data ( KIOM_USER or admin )
setwd("C:/KIOM_USER/admin/Documents/GitHub/LongitudinalNC")
# Read your data ( KIOM_USER or admin )
setwd("C:/KIOM_USER/admin/Documents/GitHub/LongitudinalNC")
# Read your data ( KIOM_USER or admin )
setwd("C:/KIOM_USER/admin/Documents/GitHub/LongitudinalNC")
# Read your data ( KIOM_USER or admin )
setwd("C:/Users/KIOM_USER/Documents/GitHub/LongitudinalNC")
df <- read.csv("Longitudinal_StableNCvsProgressiveNC.csv",
header = TRUE, stringsAsFactors = FALSE, na.strings = c("", "NA"))
df <- df %>% add_count(USUBJID, name = "visit_count")
df$COGNITIVESTAT <- df$COGNITIVESTAT %>%
str_replace_all("\\.", "")   %>%      # Remove all dots
str_trim(side = "both")       # Remove leading/trailing spaces
view(dfSummary(df ))
df.long <- df %>%
add_count(USUBJID, name = "visit_count") %>%
mutate(
# Treat SMI as CN
COGNITIVESTAT = ifelse(COGNITIVESTAT == "SMI", "CN", COGNITIVESTAT)
)
# Keep only subjects with at least 2 valid records
df.long_multi <- df.long %>%
group_by(USUBJID) %>%
filter(n() >= 2) %>%
ungroup()
(df_changes <- df.long_multi %>%
arrange(USUBJID, year) %>%  # ensure chronological order
group_by(USUBJID) %>%
summarise(
#Status_Changed = n_distinct(COGNITIVESTAT, na.rm = TRUE) > 1,
Transitions = paste(COGNITIVESTAT, collapse = " -> ")
))
(df_summary <- df_changes %>%
group_by(Transitions) %>%
summarise(Count = n()) %>%
mutate( Percentage = round(Count / sum(Count) * 100, 1)) %>%
arrange(desc(Count)))
#df_demo <- df.long_multi %>% select( Group, SEX:EDUYR, MMSE,AGE)
view(dfSummary(df.long_multi ))
#ONly take note of inital and final transitions
df_overall <- df.long_multi %>%
mutate(
COGNITIVESTAT = case_when(
COGNITIVESTAT %in% c("aMCI", "naMCI") ~ "MCI",
COGNITIVESTAT == "SMI" ~ "CN",
TRUE ~ COGNITIVESTAT
)
) %>%
arrange(USUBJID, year) %>%
group_by(USUBJID) %>%
mutate(
Initial_Status = first(COGNITIVESTAT),
Final_Status   = last(COGNITIVESTAT)
) %>%
mutate(
Transition = paste(Initial_Status, "->", Final_Status),
Change_Type = case_when(
Initial_Status == "CN" & Final_Status == "CN" ~ "StableCN",
Initial_Status == "CN" & Final_Status == "MCI" ~ "ProgressiveCN",
TRUE ~ NA_character_
)
) %>%
ungroup()
view(dfSummary(df_overall ))
(df_transition_summary <- df_overall %>%
group_by(Transition) %>%
summarise(
Count = n(),
) %>%
mutate(
Percentage = round(Count / sum(Count) * 100, 1)
) %>%
arrange(desc(Count)))
df_long.analysis <- df_overall %>%
mutate(datetest = mdy(datetest)) %>%
group_by(USUBJID) %>%
arrange(datetest) %>%
mutate(
baseline_date = min(datetest, na.rm = TRUE),
elapsed_years = as.numeric(difftime(datetest, baseline_date, units="days")) / 365.25
) %>%
select(-baseline_date) %>%
ungroup()
#get Unique Particpants for analysis
df_unique_transitions <- df_overall %>%
select(USUBJID, Transition, Change_Type) %>%  # keep only relevant columns
distinct()  # keep only unique rows by ID, Transition, Change_Type
(df_summary <- df_unique_transitions %>%
group_by(Transition, Change_Type) %>%
summarise(
Count = n(),
) %>%
mutate(
Percentage = round(Count / sum(Count) * 100, 1)
) %>%
arrange(desc(Count)))
df_long.analysis <- df_overall  %>%   mutate_if(is.character, as.factor) %>%
add_count(USUBJID, name = "visit_count") #%>% filter(Transition != "CN -> CN")
# Relevel Change_Type with "Stable" as reference
df_long.analysis$Change_Type <- relevel(factor(df_long.analysis$Change_Type), ref = "StableCN")
view(dfSummary(df_long.analysis ))
#get Unique Particpants for analysis
df_unique_transitions <- df_long.analysis %>%
select(USUBJID, Transition, Change_Type) %>%  # keep only relevant columns
distinct()  # keep only unique rows by ID, Transition, Change_Type
(df_summary <- df_unique_transitions %>%
group_by(Transition, Change_Type) %>%
summarise(
Count = n(),
) %>%
mutate(
Percentage = round(Count / sum(Count) * 100, 1)
) %>%
arrange(desc(Count)))
#df_demo <- df.long_multi %>% select( Group, SEX:EDUYR, MMSE,AGE)
view(dfSummary(df.long_multi ))
# 0) Safe numeric cleaner
clean_numeric <- function(x) {
if (is.numeric(x)) return(x)
x <- as.character(x)
x <- trimws(x)
x[x == ""] <- NA
suppressWarnings(readr::parse_number(x))
}
# 1) Shapiro-gated test: return one-row tibble with p.value, method, and per-group Shapiro p
cont_test_sw <- function(data, variable, by, ...) {
d <- data |>
dplyr::select(all_of(c(variable, by))) |>
tidyr::drop_na()
if (!is.factor(d[[by]])) d[[by]] <- factor(d[[by]])
# If not exactly 2 groups or too few obs in any group -> Wilcoxon
if (nlevels(d[[by]]) != 2L || any(table(d[[by]]) < 2L)) {
res <- suppressWarnings(stats::wilcox.test(as.formula(paste(variable, "~", by)),
data = d, exact = FALSE))
return(tibble(
p.value = res$p.value,
method  = "Wilcoxon rank-sum (insufficient groups/n)"
))
}
# Shapiro-Wilk per group with size bounds
sw_list <- tapply(d[[variable]], d[[by]], function(v) {
v <- v[is.finite(v)]
n <- length(v)
if (n < 3 || n > 5000) return(NA_real_)
suppressWarnings(stats::shapiro.test(v)$p.value)
})
# Prepare Shapiro columns
extra <- as.list(sw_list)
names(extra) <- paste0("shapiro_p_", names(extra))
normal_in_both <- all(!is.na(unlist(sw_list)) & unlist(sw_list) >= 0.05)
if (isTRUE(normal_in_both)) {
res <- stats::t.test(as.formula(paste(variable, "~", by)),
data = d, var.equal = FALSE)
tibble(
p.value = res$p.value,
method  = "Welch t-test (Shapiro p>=0.05 within groups)"
) |>
tibble::add_column(!!!extra)
} else {
res <- suppressWarnings(stats::wilcox.test(as.formula(paste(variable, "~", by)),
data = d, exact = FALSE))
tibble(
p.value = res$p.value,
method  = "Wilcoxon rank-sum (Shapiro non-normal in ≥1 group)"
) |>
tibble::add_column(!!!extra)
}
}
# 2) Append “Test” and “Shapiro p_*” columns to table_body without join
append_test_and_shapiro <- function(tbl) {
tb <- tbl$table_body
tr <- tbl$meta_data$test_result
if (is.null(tr) || length(tr) == 0) return(tbl)
# Ensure target columns exist
tb$Test <- NA_character_
# Collect all Shapiro column names present across df_result
sh_cols <- unique(unlist(lapply(tr, function(x) {
nm <- names(x$df_result)
nm[grepl("^shapiro_p_", nm)]
})))
for (sh in sh_cols) tb[[sh]] <- NA_real_
# Map test results in order to label rows (one p/test per variable label)
label_idx <- which(tb$row_type == "label")
n <- min(length(label_idx), length(tr))
for (k in seq_len(n)) {
i <- label_idx[k]
dfres <- tr[[k]]$df_result
if (!is.null(dfres)) {
if ("method" %in% names(dfres)) tb$Test[i] <- as.character(dfres$method)[1]
for (sh in sh_cols) {
if (sh %in% names(dfres)) tb[[sh]][i] <- dfres[[sh]][1]
}
}
}
# Assign back and add headers/format
tbl$table_body <- tb
tbl <- modify_header(tbl, Test ~ "Test")
if (length(sh_cols)) {
tbl <- modify_header(tbl, all_of(sh_cols) ~ "Shapiro p")
tbl <- modify_fmt_fun(tbl, columns = all_of(sh_cols),
~ style_pvalue(.x, digits = 3))
}
tbl
}
# 3) Bioimpedance list
bioimpedance_vars <- c(
"bmi", "ac", "whr", "pbcm", "pbf", "bmr", "tbw_ffm",
"ecw_tcw", "PA50_total", "ECW_ICW_upper", "ECW_ICW_lower",
"Water_Lean_upper", "Water_Lean_lower",
"R_upper", "R_lower", "Xc_upper", "Xc_lower",
"PA_upper", "PA_lower", "R_H_upper", "Xc_H_upper", "R_H_lower", "Xc_H_lower"
)
# 4) Baseline derivation
df_baseline <- df_long.analysis |>
group_by(USUBJID) |>
arrange(datetest, .by_group = TRUE) |>
slice_head(n = 1) |>
ungroup() |>
filter(Change_Type %in% c("StableCN", "ProgressiveCN"))
# Optional: ensure visit_count exists from examination_count
if (!("visit_count" %in% names(df_baseline)) && ("examination_count" %in% names(df_baseline))) {
df_baseline <- df_baseline |> mutate(visit_count = examination_count)
}
# 5) Clinical/cognitive selection & clean
age_idx <- match("AGE", names(df_baseline))
edu_idx <- match("EDUYR", names(df_baseline))
span_cols <- if (!is.na(age_idx) && !is.na(edu_idx) && age_idx <= edu_idx) {
names(df_baseline)[age_idx:edu_idx]
} else character(0)
cols_table1 <- c(
"Change_Type", span_cols,
"gds","kdsq","sysbp","diabp","visit_count","MMSE",
"SNSB_attention","SNSB_language","SNSB_visuospatial","SNSB_memory","SNSB_frontal"
) |> unique()
df_table1 <- df_baseline |>
select(any_of(cols_table1)) |>
mutate(across(-Change_Type, clean_numeric))
# 6) Bioimpedance selection & clean
df_bia_baseline <- df_baseline |>
select(Change_Type, any_of(bioimpedance_vars)) |>
mutate(across(-Change_Type, clean_numeric))
# 7) Tables with Shapiro→test, then append visible Test & Shapiro columns
# Note: If visit_count là đo lường liên tục, có thể ép continuous trong 'type' để tránh Chi-square.
tbl_table1 <- df_table1 |>
tbl_summary(
by = Change_Type,
type = list(
all_continuous() ~ "continuous",
MMSE ~ "continuous"
# , visit_count ~ "continuous"  # bật nếu muốn so sánh liên tục
),
statistic = list(
all_continuous() ~ "{mean} ({sd})",
all_categorical() ~ "{n} / {N} ({p}%)"
),
digits = all_continuous() ~ 2,
missing_text = "(Missing)"
) |>
add_p(
test = list(
all_continuous() ~ cont_test_sw,
# visit_count ~ "fisher.test",  # cân nhắc nếu giữ phân loại và tần số thấp
all_categorical() ~ "chisq.test"
)
) |>
bold_labels() |>
bold_p(t = 0.05)
tbl_table1 <- append_test_and_shapiro(tbl_table1)
tbl_bia <- df_bia_baseline |>
tbl_summary(
by = Change_Type,
type = all_continuous() ~ "continuous",
statistic = all_continuous() ~ "{mean} ({sd})",
digits = all_continuous() ~ 2,
missing_text = "(Missing)"
) |>
add_p(test = all_continuous() ~ cont_test_sw) |>
bold_labels() |>
bold_p(t = 0.05)
tbl_bia <- append_test_and_shapiro(tbl_bia)
# 8) Export to flextable
ft_table1 <- tbl_table1 |> as_flex_table()
ft_bia    <- tbl_bia    |> as_flex_table()
# Print (optional)
ft_table1
ft_bia
# Ensure numeric variables are numeric
numeric_vars <- c("height","weight","bmi","whr","pbcm","pbf","bmr","ecw_tcw","PA50_total","tbw_ffm",
"ECW_ICW_upper","ECW_ICW_lower","Water_Lean_upper","Water_Lean_lower",
"R_upper","R_lower","Xc_upper","Xc_lower","PA_upper","PA_lower",
"R_H_upper","R_H_lower","Xc_H_upper","Xc_H_lower", "gds")
for (v in numeric_vars) {
if (v %in% names(df_baseline)) df_baseline[[v]] <- as.numeric(df_baseline[[v]])
}
vars_table2 <- intersect(c("height", "weight", "bmi", "whr", "pbcm", "pbf", "bmr", "ecw_tcw","PA50_total", "tbw_ffm"), names(df_baseline))
vars_table3 <- intersect(c("ECW_ICW_upper", "ECW_ICW_lower", "Water_Lean_upper", "Water_Lean_lower",
"R_upper","R_lower","Xc_upper","Xc_lower","PA_upper","PA_lower",
"R_H_upper","R_H_lower","Xc_H_upper","Xc_H_lower"), names(df_baseline))
covariates <- intersect(c("AGE", "SEX", "EDUYR", "gds"), names(df_baseline))
# Hàm cải tiến để tính toán bảng so sánh với hiệu ứng kích thước (Hedges' g) đầy đủ
make_compare_table <- function(df, var, covars, group = "Change_Type") {
if (!is.numeric(df[[var]])) return(NULL)
# Mô hình hồi quy tuyến tính, điều chỉnh covariates
formula_lm <- as.formula(paste(var, "~", group, "+", paste(covars, collapse = "+")))
model <- lm(formula_lm, data = df)
emm <- suppressMessages(emmeans(model, specs = group))
pair <- pairs(emm, adjust = "tukey")
pair_df <- as.data.frame(pair)
# Lấy các nhóm
grp_lev <- levels(df[[group]])
data1 <- df[[var]][df[[group]] == grp_lev[1]]
data2 <- df[[var]][df[[group]] == grp_lev[2]]
# Tính Hedges' g và khoảng tin cậy dựa trên raw data
eff_res <- tryCatch({
effectsize::hedges_g(data1, data2)
}, error = function(e) return(NULL))
hedges_g_val <- if (!is.null(eff_res)) eff_res$Hedges_g else NA
hedges_g_ci_low <- if (!is.null(eff_res)) eff_res$CI_low else NA
hedges_g_ci_high <- if (!is.null(eff_res)) eff_res$CI_high else NA
# Tính trung bình và độ lệch chuẩn từng nhóm
means <- df %>%
group_by(.data[[group]]) %>%
summarise(
N = sum(!is.na(.data[[var]])),
Mean = mean(.data[[var]], na.rm = TRUE),
SD = sd(.data[[var]], na.rm = TRUE)
) %>%
arrange(match(.data[[group]], grp_lev))
mean_sd_1 <- sprintf("%.2f (%.2f)", means$Mean[1], means$SD[1])
mean_sd_2 <- sprintf("%.2f (%.2f)", means$Mean[2], means$SD[2])
# Tạo bảng kết quả với tất cả thông số
out <- tibble::tibble(
Variable = var,
Mean_SD_StableCN = mean_sd_1,
Mean_SD_ProgressiveCN = mean_sd_2,
Mean_Diff = pair_df$estimate[1],
CI_lower = pair_df$lower.CL[1],
CI_upper = pair_df$upper.CL[1],
p.value = pair_df$p.value[1],
Hedges_g = hedges_g_val,
Hedges_g_CI_low = hedges_g_ci_low,
Hedges_g_CI_high = hedges_g_ci_high
)
return(out)
}
# Tạo bảng so sánh hiệu ứng cho các nhóm biến như trước
table2 <- do.call(rbind, lapply(vars_table2, function(x) make_compare_table(df_baseline, x, covariates)))
table3 <- do.call(rbind, lapply(vars_table3, function(x) make_compare_table(df_baseline, x, covariates)))
# Chuyển sang flextable với in đậm p-value signifance
table2_ft <- flextable(table2) %>%
bold(j = "p.value", i = ~ p.value < 0.05) %>%
autofit()
table3_ft <- flextable(table3) %>%
bold(j = "p.value", i = ~ p.value < 0.05) %>%
autofit()
# In bảng ra console hoặc tài liệu
print(table2_ft)
print(table3_ft)
